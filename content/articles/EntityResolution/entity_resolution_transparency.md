# Entity Resolution: The Master Key to AI's Black Boxes

*Part 1: When Algorithms Know More About You Than You Know About Yourself*

Three data points walk into an algorithm: a credit score from 2019, a LinkedIn profile update from last Tuesday, and a utility payment record from some database you've never heard of. The algorithm sees what you cannot—that these scattered fragments belong to the same person. More troubling, it sees patterns you didn't know existed.

This is entity resolution in action. The computational art of stitching together fragments of information across databases, platforms, and time to build complete pictures of people, places, and things.¹ It's the technology that lets Netflix know you're the same person who watched three episodes of a Korean drama at 2 AM and the one who rated a documentary about sustainable mining five stars last month.

But here's where things get interesting for those tracking AI's accountability problem: entity resolution might be both the disease and the cure.

## The Invisible Infrastructure of Recognition

Every day, algorithms make thousands of decisions about you based on data you can't see, using connections you didn't authorize. Your phone recognizes your face. Your bank verifies your identity. Your insurance company calculates your risk. Each system maintains its own version of "you"—and entity resolution is the glue that connects these scattered selves.

The technology sounds mundane until you realize its scope. When you apply for a loan, the bank's algorithm doesn't just check your credit score. It cross-references your application against dozens of databases, identifying patterns across your digital footprint.² Late payments from five years ago. Social media activity. Shopping habits. Employment history. Location data. The algorithm builds a composite picture more complete than your own memory.

This isn't speculation—it's standard practice. Consumer reporting agencies like LexisNexis maintain profiles on nearly every American adult, combining traditional credit data with "alternative" sources: online behavior, retail purchases, insurance claims, criminal records, property ownership, professional licenses, and social networks.³ These profiles inform decisions about employment, housing, insurance, and financial services.

The companies call it "comprehensive risk assessment." Communities call it surveillance capitalism with a credit score.

## The Extraction Connection

Remember the mining algorithm from our last conversation—the one that could recommend community displacement without explaining its reasoning? Entity resolution powers these systems too.

When extraction companies scout new sites, their algorithms don't just analyze geological surveys. They map social networks. Identify community leaders. Track property ownership patterns. Predict resistance levels based on historical data from similar locations.⁴ They build detailed profiles of every person who might oppose development, every organization that might file lawsuits, every politician who might withdraw permits.

The algorithms know which families have lived on the land for generations and which newcomers might accept relocation payments. They can predict which community members are likely to organize protests and which might become internal advocates for development. They identify traditional leaders versus official government representatives, mapping informal power structures that determine how decisions actually get made.

This isn't conspiracy theory—it's business intelligence. The same entity resolution techniques that help Netflix recommend movies help extraction companies map resistance and optimize community engagement strategies.

But here's the plot twist: the same technology that makes these invasive profiles possible might also be our best tool for forcing accountability.

## Cracking Open the Black Box

Traditional approaches to AI transparency focus on algorithms—can we make neural networks explainable? Can we audit decision trees? Can we force companies to reveal their source code? These efforts matter, but they miss something crucial.

The black box isn't just the algorithm. It's the data.

Most AI systems make decisions based on entity resolution—connecting scattered information to build complete pictures. The algorithmic processing might be sophisticated, but the real power lies in data integration.⁵ When we can see how systems connect information about us, we can begin to understand how they see us.

Entity resolution creates audit trails. Every connection between data points represents a decision—implicit or explicit—about what information belongs together. These decisions reveal assumptions, biases, and priorities that remain hidden when we focus only on algorithmic logic.

Consider the mining community displacement example. The algorithm's recommendation might seem arbitrary, but entity resolution reveals the underlying logic. Which databases did it consult? How did it define "community leadership"? What connections did it draw between traditional land use and legal property ownership? How did it weight resistance patterns from other locations?

These questions become answerable when we can trace entity resolution processes. Not easily answerable—the technical complexity remains daunting. But answerable in principle, which is more than we can say for most AI transparency efforts.

## The Accountability Architecture

Three companies have pioneered approaches that turn entity resolution from surveillance tool into accountability mechanism:

**Palantir's Gotham** demonstrates how entity resolution can create comprehensive audit trails. Every data connection gets logged. Every algorithmic inference traces back to specific information sources.⁶ Intelligence analysts can see not just what the system concluded, but why it connected particular data points. When the system makes mistakes—connecting innocent individuals to criminal networks—investigators can trace the error back to specific data integration decisions.

**Socrata's approach to government transparency** shows how entity resolution can serve public accountability. Instead of hiding data connections, the platform makes them visible to citizens.⁷ Residents can see how their city connects budget allocations to service outcomes, how planning decisions link to developer relationships, how resource distributions correlate with demographic patterns. The technology reveals government logic rather than obscuring it.

**Academic research platforms** like VIVO demonstrate entity resolution for knowledge discovery rather than surveillance. These systems connect researchers, publications, grants, and institutions—but the connections remain open for verification and challenge.⁸ Scientists can see how the system links their work to broader research networks, correct misattributed publications, and understand how algorithmic recommendations get generated.

Each example suggests the same possibility: entity resolution becomes accountable when its connections remain visible and challengeable.

## What Comes Next

The technology works. The surveillance capabilities are real. The accountability potential exists.

The question isn't whether entity resolution will continue expanding—it's too useful and too profitable to abandon. The question is whether it expands with or without community agency.

Next week, we'll explore how communities are demanding veto power over algorithmic representations and what technical implementations make that possible. Because transparency without agency is just better-documented oppression.

---

*This article continues our series on AI accountability in high-stakes industries. Next: "Community Veto Systems: When Algorithms Must Ask Permission."*

---

## References

1. Christophides, V., Efthymiou, V., Palpanas, T., Papadakis, G., & Stefanidis, K. (2015). *End-to-End Entity Resolution for Big Data: A Survey*. arXiv preprint arXiv:1905.06397. Available at: https://arxiv.org/abs/1905.06397

2. Ratcliffe, J. (2020). "The Hidden Algorithms That Power Banking Decisions." *Harvard Business Review*, 15 March. Available at: https://hbr.org/2020/03/the-hidden-algorithms-that-power-banking-decisions

3. Hurley, M. & Adebayo, J. (2017). "Credit Scoring in the Era of Big Data." *Yale Journal of Law and Technology*, 18(1), 148-216. Available at: https://yjolt.org/sites/default/files/18_yale_j.l._tech_148_2016.pdf

4. Extractive Industries Transparency Initiative. (2023). "Digital Governance and Community Engagement in Resource Extraction." *EITI Guidance Note 7*. Available at: https://eiti.org/guidance-notes-and-standard-clarifications

5. Dong, X. L. & Srivastava, D. (2015). "Big Data Integration." *Communications of the ACM*, 58(9), 59-60. doi:10.1145/2801070

6. Palantir Technologies. (2021). "Audit and Accountability in Data Integration Platforms." *Technical Documentation*. Available at: https://www.palantir.com/docs/gotham/audit-accountability/

7. Socrata. (2022). "Open Data and Government Transparency: Technical Implementation Guide." Available at: https://dev.socrata.com/docs/transparency-implementation.html

8. VIVO Collaboration. (2020). "Semantic Web Technologies for Scholarly Communication." *Journal of Biomedical Semantics*, 11(1), 12. doi:10.1186/s13326-020-00233-1